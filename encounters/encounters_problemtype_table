import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime
from tabulate import tabulate
import pyodbc
import os

# Define the file path
file_path = 'G:/samanth473_drive/CDP/CDA-phcaserpt-1.3.0-CDA-phcaserpt-1.3.1/examples/samples/CDAR2_IG_PHCASERPT_R2_STU3.1_SAMPLE.xml'

# Extract the file name from the file path
file_name = os.path.basename(file_path)

# Load and parse the XML file
tree = ET.parse(file_path)
root = tree.getroot()

# Define the namespace
ns = {'n1': 'urn:hl7-org:v3'}

# Extract additional diagnosis data
additional_diagnosis_data = []
source = "Encounters"
insert_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Function to extract text or return empty string if not found
def get_text_or_default(element, xpath, ns, default=""):
    found = element.find(xpath, ns)
    return found.text if found is not None else default

# Find the "Encounters" section
encounters_section = root.find(".//n1:section[n1:title='Encounters']", ns)

# Loop through each tr in the Encounters section to find the specific nested tables
for td in encounters_section.findall(".//n1:td[@colspan='20']", ns):
    for table in td.findall(".//n1:table", ns):
        headers = [get_text_or_default(th, ".", ns) for th in table.findall(".//n1:thead//n1:th", ns)]
        if "Problem Type" in headers and "Date(s)" in headers:
            for tr in table.findall(".//n1:tbody//n1:tr", ns):
                tds = tr.findall("n1:td", ns)
                if len(tds) == 3:  # Ensure it's the correct number of columns
                    problem_type = get_text_or_default(tds[0], ".", ns)
                    problem = get_text_or_default(tds[1], ".", ns)
                    dates = get_text_or_default(tds[2], ".", ns)
                    row = [problem_type, problem, dates, source, file_name, insert_datetime]
                    # Avoid adding duplicates
                    if row not in additional_diagnosis_data:
                        additional_diagnosis_data.append(row)

# Create DataFrame for Additional Diagnosis data
additional_diagnosis_df = pd.DataFrame(additional_diagnosis_data, columns=["PROBLEM_TYPE", "PROBLEM", "DIAGNOSIS_DATE", "SOURCE", "FILE_NAME", "INSERT_DATETIME"])

# Print Additional Diagnosis DataFrame as table
print("\nAdditional Diagnosis Data:")
print(tabulate(additional_diagnosis_df, headers='keys', tablefmt='psql'))

# Define SQL Server connection details
server = 'Samanth'
database = 'ClinicalDocument'
schema = 'cdg'
table_name = 'AdditionalDiagnosis'

# Establish connection to SQL Server
conn = pyodbc.connect(f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;')
cursor = conn.cursor()

# Function to get the current columns of a table
def get_current_columns(cursor, schema, table_name):
    cursor.execute(f"""
    SELECT COLUMN_NAME 
    FROM INFORMATION_SCHEMA.COLUMNS 
    WHERE TABLE_SCHEMA = '{schema}' AND TABLE_NAME = '{table_name}'
    """)
    return [row.COLUMN_NAME for row in cursor.fetchall()]

# Function to add missing columns to the table
def add_missing_columns(cursor, schema, table_name, columns):
    existing_columns = get_current_columns(cursor, schema, table_name)
    for column in columns:
        if column not in existing_columns:
            cursor.execute(f"ALTER TABLE [{schema}].[{table_name}] ADD [{column}] NVARCHAR(MAX)")

# Check if table exists, create if not
cursor.execute(f"""
IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES 
               WHERE TABLE_SCHEMA = '{schema}' AND TABLE_NAME = '{table_name}')
BEGIN
    CREATE TABLE [{schema}].[{table_name}] (
        [ID] INT IDENTITY(1,1) PRIMARY KEY,
        [PROBLEM_TYPE] NVARCHAR(MAX),
        [PROBLEM] NVARCHAR(MAX),
        [DIAGNOSIS_DATE] NVARCHAR(MAX),
        [SOURCE] NVARCHAR(MAX),
        [FILE_NAME] NVARCHAR(MAX),
        [INSERT_DATETIME] NVARCHAR(MAX)
    )
END
""")

# Ensure all columns from DataFrame are present in the table
add_missing_columns(cursor, schema, table_name, additional_diagnosis_df.columns)

# Truncate the table if it has rows
cursor.execute(f"""
IF EXISTS (SELECT 1 FROM [{schema}].[{table_name}])
BEGIN
    TRUNCATE TABLE [{schema}].[{table_name}]
END
""")

# Dynamically generate the insert statement based on DataFrame columns
columns_str = ', '.join(f'[{col}]' for col in additional_diagnosis_df.columns)
values_str = ', '.join('?' for _ in additional_diagnosis_df.columns)

insert_sql = f"""
INSERT INTO [{schema}].[{table_name}] ({columns_str})
VALUES ({values_str})
"""

# Insert DataFrame to SQL Server
for index, row in additional_diagnosis_df.iterrows():
    cursor.execute(insert_sql, tuple(row))

# Commit the transaction
conn.commit()

# Close the connection
conn.close()

print('\nData written to SQL Server successfully.')
